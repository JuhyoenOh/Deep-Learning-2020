{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats\n",
    "## Kaggle Dataset의 전부를 이용한 개, 고양이 구분\n",
    "### Dog Image: 12,500개, Cat Image: 12,500개, 총 25,000개\n",
    "### 출처: [pontoregende GitHub](https://github.com/pontorezende/Dogs-vs-Cats-Redux-with-CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2, os, random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='dogs-vs-cats/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## used for resize and in our model\n",
    "ROW, COL = 96, 96\n",
    "\n",
    "dogs, cats = [], []\n",
    "y_dogs, y_cats = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definition to load all our dog images\n",
    "def load_dogs():\n",
    "    print('Loading all dog images\\n')\n",
    "    dog_path = os.path.join(path, 'dog*')\n",
    "    for dog_img in glob(dog_path):\n",
    "        dog = cv2.imread(dog_img)\n",
    "        dog = cv2.cvtColor(dog, cv2.COLOR_BGR2GRAY)\n",
    "        dog = cv2.resize(dog, (ROW, COL))\n",
    "        dog = image.img_to_array(dog)\n",
    "        dogs.append(dog)\n",
    "    print('All dog images loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definition to load all our cat images\n",
    "def load_cats():\n",
    "    print('Loading all cat images\\n')\n",
    "    cat_path = os.path.join(path, 'cat*')\n",
    "    for cat_img in glob(cat_path):\n",
    "        cat = cv2.imread(cat_img)\n",
    "        cat = cv2.cvtColor(cat, cv2.COLOR_BGR2GRAY)\n",
    "        cat = cv2.resize(cat, (ROW, COL))\n",
    "        cat = image.img_to_array(cat)\n",
    "        cats.append(cat)\n",
    "    print('All cat images loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dog images\n",
      "\n",
      "All dog images loaded\n"
     ]
    }
   ],
   "source": [
    "load_dogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all cat images\n",
      "\n",
      "All cat images loaded\n"
     ]
    }
   ],
   "source": [
    "load_cats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['dog', 'cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in case we want to see if our images was saved correctly in arrays we can use those codes\n",
    "def show_dogs():\n",
    "    plt.figure(figsize=(12,8))    \n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        img = image.array_to_img(random.choice(dogs))\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.title('Supposed to be a {}'.format(classes[0]))        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cats():\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        img = image.array_to_img(random.choice(cats))\n",
    "        plt.imshow(img)\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.title('Supposed to be a {}'.format(classes[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## just change the labels for 0 and  1\n",
    "y_dogs = [1 for item in enumerate(dogs)]\n",
    "y_cats = [0 for item in enumerate(cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting everything to Numpy array to fit in our model\n",
    "## them creating a X and target file like we used to see\n",
    "## in Machine and Deep Learning models\n",
    "dogs = np.asarray(dogs).astype('float32')\n",
    "cats = np.asarray(cats).astype('float32')\n",
    "y_dogs = np.asarray(y_dogs).astype('int32')\n",
    "y_cats = np.asarray(y_cats).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit values between 0 and 1\n",
    "dogs /= 255\n",
    "cats /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((dogs,cats), axis=0)\n",
    "y = np.concatenate((y_dogs, y_cats), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_CHANNEL = 1\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCH = 10\n",
    "VERBOSE = 1\n",
    "VALIDAION_SPLIT = .2\n",
    "OPTIM = Adam()\n",
    "N_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-Hot Encoding - train\n",
    "y = tf.keras.utils.to_categorical(y, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, \n",
    "                                                    test_size=.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 96, 96, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 96, 96, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 96, 96, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 18,940,898\n",
      "Trainable params: 18,940,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Here is our model as a CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', input_shape=(ROW, COL, IMG_CHANNEL), activation='relu'),\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(.5),\n",
    "    Dense(N_CLASSES, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"model/dogs_vs_cats-cnn.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=VERBOSE, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "15872/16000 [============================>.] - ETA: 1s - loss: 0.6887 - accuracy: 0.5374\n",
      "Epoch 00001: val_loss improved from inf to 0.66773, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "16000/16000 [==============================] - 212s 13ms/sample - loss: 0.6884 - accuracy: 0.5383 - val_loss: 0.6677 - val_accuracy: 0.5880\n",
      "Epoch 2/10\n",
      "15872/16000 [============================>.] - ETA: 1s - loss: 0.6412 - accuracy: 0.6366\n",
      "Epoch 00002: val_loss improved from 0.66773 to 0.60539, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "16000/16000 [==============================] - 220s 14ms/sample - loss: 0.6409 - accuracy: 0.6371 - val_loss: 0.6054 - val_accuracy: 0.6660\n",
      "Epoch 3/10\n",
      "15872/16000 [============================>.] - ETA: 1s - loss: 0.5735 - accuracy: 0.7038\n",
      "Epoch 00003: val_loss improved from 0.60539 to 0.54596, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "16000/16000 [==============================] - 220s 14ms/sample - loss: 0.5737 - accuracy: 0.7036 - val_loss: 0.5460 - val_accuracy: 0.7207\n",
      "Epoch 4/10\n",
      "15872/16000 [============================>.] - ETA: 1s - loss: 0.5236 - accuracy: 0.7380\n",
      "Epoch 00004: val_loss improved from 0.54596 to 0.52236, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "16000/16000 [==============================] - 211s 13ms/sample - loss: 0.5232 - accuracy: 0.7383 - val_loss: 0.5224 - val_accuracy: 0.7383\n",
      "Epoch 5/10\n",
      "15872/16000 [============================>.] - ETA: 1s - loss: 0.4878 - accuracy: 0.7603\n",
      "Epoch 00005: val_loss improved from 0.52236 to 0.48973, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "16000/16000 [==============================] - 211s 13ms/sample - loss: 0.4874 - accuracy: 0.7606 - val_loss: 0.4897 - val_accuracy: 0.7595\n",
      "Epoch 6/10\n",
      "15872/16000 [============================>.] - ETA: 1s - loss: 0.4525 - accuracy: 0.7843\n",
      "Epoch 00006: val_loss improved from 0.48973 to 0.45925, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "16000/16000 [==============================] - 211s 13ms/sample - loss: 0.4525 - accuracy: 0.7843 - val_loss: 0.4593 - val_accuracy: 0.7797\n",
      "Epoch 7/10\n",
      "15872/16000 [============================>.] - ETA: 1s - loss: 0.4091 - accuracy: 0.8124\n",
      "Epoch 00007: val_loss improved from 0.45925 to 0.44984, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "16000/16000 [==============================] - 214s 13ms/sample - loss: 0.4090 - accuracy: 0.8123 - val_loss: 0.4498 - val_accuracy: 0.7843\n",
      "Epoch 8/10\n",
      "15872/16000 [============================>.] - ETA: 1s - loss: 0.3622 - accuracy: 0.8369\n",
      "Epoch 00008: val_loss did not improve from 0.44984\n",
      "16000/16000 [==============================] - 211s 13ms/sample - loss: 0.3621 - accuracy: 0.8370 - val_loss: 0.4545 - val_accuracy: 0.7885\n",
      "Epoch 9/10\n",
      "15872/16000 [============================>.] - ETA: 1s - loss: 0.3117 - accuracy: 0.8624\n",
      "Epoch 00009: val_loss did not improve from 0.44984\n",
      "16000/16000 [==============================] - 209s 13ms/sample - loss: 0.3115 - accuracy: 0.8624 - val_loss: 0.4611 - val_accuracy: 0.7947\n",
      "Epoch 10/10\n",
      "15872/16000 [============================>.] - ETA: 1s - loss: 0.2597 - accuracy: 0.8913\n",
      "Epoch 00010: val_loss did not improve from 0.44984\n",
      "16000/16000 [==============================] - 210s 13ms/sample - loss: 0.2603 - accuracy: 0.8911 - val_loss: 0.4881 - val_accuracy: 0.7943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29515bc1208>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, validation_split=VALIDAION_SPLIT,shuffle=True,callbacks=[checkpointer, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('model/dogs_vs_cats-cnn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 - 11s - loss: 0.4549 - accuracy: 0.7878\n",
      "MODEL ACCURACY: 0.78780\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, Y_test, verbose=2)\n",
    "print('MODEL ACCURACY: %.5f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
