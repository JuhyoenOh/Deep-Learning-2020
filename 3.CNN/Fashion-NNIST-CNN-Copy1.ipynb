{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MhoQ0WE77laV"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "_ckMIh7O7s6D"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "vasWnqRgy1H4"
   },
   "outputs": [],
   "source": [
    "#@title MIT License\n",
    "#\n",
    "# Copyright (c) 2017 François Chollet\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzLKpmZICaWN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjnLH5S2CaWx"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 최적화 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zW5k_xz1CaWX"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = MODEL_DIR + \"Fashion-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.5486 - accuracy: 0.8067\n",
      "Epoch 00001: val_loss improved from inf to 0.34226, saving model to ./model/Fashion-01-0.3423.hdf5\n",
      "60000/60000 [==============================] - 44s 740us/sample - loss: 0.5478 - accuracy: 0.8069 - val_loss: 0.3423 - val_accuracy: 0.8768\n",
      "Epoch 2/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.3488 - accuracy: 0.8769\n",
      "Epoch 00002: val_loss improved from 0.34226 to 0.30492, saving model to ./model/Fashion-02-0.3049.hdf5\n",
      "60000/60000 [==============================] - 43s 722us/sample - loss: 0.3487 - accuracy: 0.8770 - val_loss: 0.3049 - val_accuracy: 0.8891\n",
      "Epoch 3/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.3017 - accuracy: 0.8932\n",
      "Epoch 00003: val_loss improved from 0.30492 to 0.26812, saving model to ./model/Fashion-03-0.2681.hdf5\n",
      "60000/60000 [==============================] - 44s 730us/sample - loss: 0.3019 - accuracy: 0.8931 - val_loss: 0.2681 - val_accuracy: 0.9040\n",
      "Epoch 4/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.2702 - accuracy: 0.9016\n",
      "Epoch 00004: val_loss improved from 0.26812 to 0.25018, saving model to ./model/Fashion-04-0.2502.hdf5\n",
      "60000/60000 [==============================] - 43s 722us/sample - loss: 0.2703 - accuracy: 0.9016 - val_loss: 0.2502 - val_accuracy: 0.9070\n",
      "Epoch 5/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.2480 - accuracy: 0.9101\n",
      "Epoch 00005: val_loss improved from 0.25018 to 0.23773, saving model to ./model/Fashion-05-0.2377.hdf5\n",
      "60000/60000 [==============================] - 43s 723us/sample - loss: 0.2478 - accuracy: 0.9101 - val_loss: 0.2377 - val_accuracy: 0.9123\n",
      "Epoch 6/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.2303 - accuracy: 0.9176\n",
      "Epoch 00006: val_loss improved from 0.23773 to 0.23107, saving model to ./model/Fashion-06-0.2311.hdf5\n",
      "60000/60000 [==============================] - 43s 723us/sample - loss: 0.2301 - accuracy: 0.9177 - val_loss: 0.2311 - val_accuracy: 0.9154\n",
      "Epoch 7/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.2139 - accuracy: 0.9219\n",
      "Epoch 00007: val_loss improved from 0.23107 to 0.22281, saving model to ./model/Fashion-07-0.2228.hdf5\n",
      "60000/60000 [==============================] - 43s 721us/sample - loss: 0.2138 - accuracy: 0.9220 - val_loss: 0.2228 - val_accuracy: 0.9207\n",
      "Epoch 8/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1963 - accuracy: 0.9284\n",
      "Epoch 00008: val_loss improved from 0.22281 to 0.22234, saving model to ./model/Fashion-08-0.2223.hdf5\n",
      "60000/60000 [==============================] - 43s 722us/sample - loss: 0.1964 - accuracy: 0.9284 - val_loss: 0.2223 - val_accuracy: 0.9214\n",
      "Epoch 9/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1861 - accuracy: 0.9314\n",
      "Epoch 00009: val_loss improved from 0.22234 to 0.21425, saving model to ./model/Fashion-09-0.2143.hdf5\n",
      "60000/60000 [==============================] - 44s 733us/sample - loss: 0.1863 - accuracy: 0.9313 - val_loss: 0.2143 - val_accuracy: 0.9242\n",
      "Epoch 10/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1751 - accuracy: 0.9347\n",
      "Epoch 00010: val_loss did not improve from 0.21425\n",
      "60000/60000 [==============================] - 44s 726us/sample - loss: 0.1752 - accuracy: 0.9347 - val_loss: 0.2264 - val_accuracy: 0.9195\n",
      "Epoch 11/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9395\n",
      "Epoch 00011: val_loss did not improve from 0.21425\n",
      "60000/60000 [==============================] - 43s 720us/sample - loss: 0.1618 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9209\n",
      "Epoch 12/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1538 - accuracy: 0.9417\n",
      "Epoch 00012: val_loss improved from 0.21425 to 0.21223, saving model to ./model/Fashion-12-0.2122.hdf5\n",
      "60000/60000 [==============================] - 43s 722us/sample - loss: 0.1538 - accuracy: 0.9417 - val_loss: 0.2122 - val_accuracy: 0.9303\n",
      "Epoch 13/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1476 - accuracy: 0.9439\n",
      "Epoch 00013: val_loss improved from 0.21223 to 0.20787, saving model to ./model/Fashion-13-0.2079.hdf5\n",
      "60000/60000 [==============================] - 43s 721us/sample - loss: 0.1479 - accuracy: 0.9437 - val_loss: 0.2079 - val_accuracy: 0.9290\n",
      "Epoch 14/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 0.9491\n",
      "Epoch 00014: val_loss did not improve from 0.20787\n",
      "60000/60000 [==============================] - 43s 719us/sample - loss: 0.1361 - accuracy: 0.9491 - val_loss: 0.2166 - val_accuracy: 0.9281\n",
      "Epoch 15/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1291 - accuracy: 0.9503\n",
      "Epoch 00015: val_loss did not improve from 0.20787\n",
      "60000/60000 [==============================] - 43s 717us/sample - loss: 0.1291 - accuracy: 0.9503 - val_loss: 0.2096 - val_accuracy: 0.9313\n",
      "Epoch 16/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1227 - accuracy: 0.9533\n",
      "Epoch 00016: val_loss did not improve from 0.20787\n",
      "60000/60000 [==============================] - 43s 720us/sample - loss: 0.1228 - accuracy: 0.9532 - val_loss: 0.2126 - val_accuracy: 0.9329\n",
      "Epoch 17/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1178 - accuracy: 0.9558\n",
      "Epoch 00017: val_loss did not improve from 0.20787\n",
      "60000/60000 [==============================] - 43s 720us/sample - loss: 0.1178 - accuracy: 0.9558 - val_loss: 0.2236 - val_accuracy: 0.9300\n",
      "Epoch 18/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.9574\n",
      "Epoch 00018: val_loss did not improve from 0.20787\n",
      "60000/60000 [==============================] - 43s 719us/sample - loss: 0.1126 - accuracy: 0.9574 - val_loss: 0.2225 - val_accuracy: 0.9312\n",
      "Epoch 19/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1066 - accuracy: 0.9603\n",
      "Epoch 00019: val_loss did not improve from 0.20787\n",
      "60000/60000 [==============================] - 44s 731us/sample - loss: 0.1066 - accuracy: 0.9602 - val_loss: 0.2244 - val_accuracy: 0.9311\n",
      "Epoch 20/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.1016 - accuracy: 0.9611\n",
      "Epoch 00020: val_loss did not improve from 0.20787\n",
      "60000/60000 [==============================] - 44s 740us/sample - loss: 0.1016 - accuracy: 0.9611 - val_loss: 0.2327 - val_accuracy: 0.9314\n",
      "Epoch 21/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 0.9624\n",
      "Epoch 00021: val_loss did not improve from 0.20787\n",
      "60000/60000 [==============================] - 43s 715us/sample - loss: 0.0967 - accuracy: 0.9624 - val_loss: 0.2354 - val_accuracy: 0.9312\n",
      "Epoch 22/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9643\n",
      "Epoch 00022: val_loss did not improve from 0.20787\n",
      "60000/60000 [==============================] - 43s 720us/sample - loss: 0.0935 - accuracy: 0.9643 - val_loss: 0.2406 - val_accuracy: 0.9340\n",
      "Epoch 23/30\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 0.9640\n",
      "Epoch 00023: val_loss did not improve from 0.20787\n",
      "60000/60000 [==============================] - 43s 716us/sample - loss: 0.0932 - accuracy: 0.9639 - val_loss: 0.2335 - val_accuracy: 0.9337\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30,\n",
    "                    batch_size=200, #epochs=5, verbose=2, \n",
    "                    callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model/Fashion-13-0.2079.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Accuracy: 0.9290\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test, verbose=0)[1]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
